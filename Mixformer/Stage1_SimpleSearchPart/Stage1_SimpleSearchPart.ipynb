{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBo1GsWCJKRf"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning > /dev/null 2>&1\n",
        "!pip install einops > /dev/null 2>&1\n",
        "!pip install timm > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf MixformerFromScratch\n",
        "!git clone https://github.com/reeWorlds/MixformerFromScratch.git\n",
        "!pip install -e \"MixformerFromScratch\"\n",
        "\n",
        "import site\n",
        "site.main()"
      ],
      "metadata": {
        "id": "X_fuf8i0JopL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  import os\n",
        "  os._exit(0)"
      ],
      "metadata": {
        "id": "_gGLDBjvJrpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from Mixformer import st1_target\n",
        "from Mixformer import st1_search"
      ],
      "metadata": {
        "id": "DsCQhRLIJsbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage1_SimpleSearchPart'"
      ],
      "metadata": {
        "id": "9lrRJHL2JzJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder_path = data_prefix\n",
        "\n",
        "train_patches_nums = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "valid_path_num = 10\n",
        "\n",
        "train_search, train_class, train_out = None, None, None\n",
        "valid_search, valid_class, valid_out = None, None, None\n",
        "\n",
        "def get_tensor_by_path(file_path, size, shape, dtype):\n",
        "  mmapped_array = np.memmap(file_path, dtype=dtype, mode='r', shape=(size,))\n",
        "  tensor = torch.from_numpy(mmapped_array)\n",
        "  return tensor.reshape(*shape)\n",
        "\n",
        "def get_data_by_num(path_num):\n",
        "  search_path = os.path.join(data_folder_path, f'patch{path_num}_search.bin')\n",
        "  search_size = 10000 * 64 * 64 * 3\n",
        "  search_tensor = get_tensor_by_path(search_path, search_size, (10000, 64, 64, 3), np.float32)\n",
        "  class_path = os.path.join(data_folder_path, f'patch{path_num}_class.bin')\n",
        "  class_size = 10000\n",
        "  class_tensor = get_tensor_by_path(class_path, class_size, (10000,), np.uint8)\n",
        "  class_tensor = class_tensor.int()\n",
        "  out_path = os.path.join(data_folder_path, f'patch{path_num}_output.bin')\n",
        "  out_size = 10000 * 64 * 64\n",
        "  out_tensor = get_tensor_by_path(out_path, out_size, (10000, 64, 64), np.uint8)\n",
        "  out_tensor = out_tensor.float() / 255.0\n",
        "  return search_tensor, class_tensor, out_tensor\n",
        "\n",
        "list_s, list_c, list_o = [], [], []\n",
        "\n",
        "for patch_num in train_patches_nums:\n",
        "  s, c, o = get_data_by_num(patch_num)\n",
        "  list_s.append(s)\n",
        "  list_c.append(c)\n",
        "  list_o.append(o)\n",
        "  print(f'Finished patch_num = {patch_num}')\n",
        "\n",
        "train_search = torch.cat(list_s, dim=0)\n",
        "train_class = torch.cat(list_c, dim=0)\n",
        "train_out = torch.cat(list_o, dim=0)\n",
        "\n",
        "valid_search, valid_class, valid_out = get_data_by_num(valid_path_num)\n",
        "gc.collect()\n",
        "\n",
        "print(f'train data shapes are s:{train_search.shape}, c:{train_class.shape}, o:{train_out.shape}')\n",
        "print(f'valid data shapes are s:{valid_search.shape}, c:{valid_class.shape}, o:{valid_out.shape}')"
      ],
      "metadata": {
        "id": "Ahp77zYBJ4mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(searches, outs, index):\n",
        "  plt.clf()\n",
        "  img_search = searches[index]\n",
        "  img_search_np = img_search.numpy()\n",
        "  img_out = outs[index]\n",
        "  img_out_np = img_out.numpy()\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(4, 4))\n",
        "  ax[0].imshow(img_search_np)\n",
        "  ax[0].set_title('Search Image')\n",
        "  ax[1].imshow(img_out_np, cmap='gray', vmin=0, vmax=1)\n",
        "  ax[1].set_title('Mask Image')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lLd8tOsuNznV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_ind_to_name = {0: 'Water', 1: 'Sand', 2: 'Grass', 3: 'Mountain', 4: 'Snow'}\n",
        "ind = 24\n",
        "print(class_ind_to_name[train_class[ind].item()])\n",
        "plot_image(train_search, train_out, ind)"
      ],
      "metadata": {
        "id": "o6Kt31abOpqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        config = st1_target.make_mixformer_config(\"medium\")\n",
        "        self.model = st1_target.MixFormer(config)\n",
        "\n",
        "    def forward(self, _search, _class):\n",
        "        return self.model(_search, _class)"
      ],
      "metadata": {
        "id": "xYMOFU8prO4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, _search, _class, _out, _class_type=None):\n",
        "        self._search = _search\n",
        "        self._class = _class\n",
        "        self._out = _out\n",
        "        if _class_type is None:\n",
        "          self._list_ind = list(range(len(_search)))\n",
        "        else:\n",
        "          self._list_ind = torch.where(_class == _class_type)[0].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._list_ind)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self._search[self._list_ind[idx]], self._class[self._list_ind[idx]], self._out[self._list_ind[idx]]"
      ],
      "metadata": {
        "id": "coaFEbffL0zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningMixFormer(pl.LightningModule):\n",
        "    def __init__(self, base_model=None):\n",
        "        super().__init__()\n",
        "        config = st1_search.make_mixformer_config(\"medium\")\n",
        "        self.model = st1_search.MixFormer(config, base_model)\n",
        "        self._class_type = None\n",
        "        self.start_lr = 1e-3\n",
        "        self.lr_gamma = 0.75\n",
        "\n",
        "    def forward(self, _search, _class):\n",
        "        return self.model(_search, _class)\n",
        "\n",
        "    def get_loss(self, out_pred, out):\n",
        "        #loss = F.binary_cross_entropy(out_pred, out)\n",
        "        loss = F.mse_loss(out_pred, out)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        _search, _class, _out = batch\n",
        "        out_pred = self.model(_search, _class)\n",
        "        loss = self.get_loss(out_pred, _out)\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _search, _class, _out = batch\n",
        "        out_pred = self.model(_search, _class)\n",
        "        loss = self.get_loss(out_pred, _out)\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.start_lr, weight_decay=1e-6)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=self.lr_gamma)\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': scheduler,\n",
        "                'interval': 'epoch',\n",
        "                'frequency': 1\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_dataset = MyDataset(train_search, train_class, train_out, self._class_type)\n",
        "        return torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        valid_dataset = MyDataset(valid_search, valid_class, valid_out, self._class_type)\n",
        "        return torch.utils.data.DataLoader(valid_dataset, batch_size=512, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "_IhthSuIL080"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainer(max_epochs):\n",
        "  checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath='my_model/',\n",
        "                                        filename='model-{epoch:02d}-{val_loss:.2f}',\n",
        "                                        save_top_k=5, mode='min')\n",
        "  csv_logger = pl_loggers.CSVLogger('logs')\n",
        "  trainer = pl.Trainer(max_epochs=max_epochs,callbacks=[checkpoint_callback],\n",
        "                       logger=csv_logger)\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "xI9YRlOWL1GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_v = 1\n",
        "base_model_path_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage1_SimpleTargetPart/models'\n",
        "base_model_path = os.path.join(base_model_path_prefix, f'model_medium_v{base_model_v}.ckpt')\n",
        "base_model = BaseModel.load_from_checkpoint(base_model_path)"
      ],
      "metadata": {
        "id": "6-t8C88FsDWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightningMixFormer(base_model.model)"
      ],
      "metadata": {
        "id": "SutppxpZL1Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stages = [1, 2]\n",
        "\n",
        "for stage in stages:\n",
        "  if stage == 1:\n",
        "    trainer = get_trainer(3)\n",
        "    model.start_lr = 5e-4\n",
        "    model.lr_gamma = 0.8\n",
        "    model._class_type = None\n",
        "    model.model.set_base_requires_grad(False)\n",
        "    trainer.fit(model)\n",
        "  elif stage == 2:\n",
        "    trainer = get_trainer(20)\n",
        "    model.start_lr = 1e-3\n",
        "    model.lr_gamma = 0.865\n",
        "    model._class_type = None\n",
        "    model.model.set_base_requires_grad(True)\n",
        "    trainer.fit(model)"
      ],
      "metadata": {
        "id": "isynxkwe8U1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "model_v = 1\n",
        "\n",
        "#source_path = '/content/logs/lightning_logs/version_1/metrics.csv'\n",
        "#dest_path = os.path.join(data_prefix, f'models/logs_medium_v{model_v}.csv')\n",
        "#shutil.copyfile(source_path, dest_path)\n",
        "\n",
        "trainer.save_checkpoint(\"model.ckpt\")\n",
        "model_checkpoint_path = os.path.join(data_prefix, f'models/model_medium_v{model_v}.ckpt')\n",
        "trainer.save_checkpoint(model_checkpoint_path)"
      ],
      "metadata": {
        "id": "dgNV1vGBL1md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(data_prefix, f'models/model_medium_v{model_v}.ckpt')\n",
        "model = LightningMixFormer.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model.eval()\n",
        "model.to('cuda')\n",
        "pass"
      ],
      "metadata": {
        "id": "JOyMoq52L15c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outputs(searches, classes, outs):\n",
        "  dataset = MyDataset(searches, classes, outs)\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=512, shuffle=False, num_workers=2)\n",
        "  all_outputs = []\n",
        "  with torch.no_grad():\n",
        "      for batch in data_loader:\n",
        "          _search = batch[0].to('cuda')\n",
        "          _class = batch[1].to('cuda')\n",
        "          outputs = model(_search, _class)\n",
        "          outputs = torch.clamp(outputs, min=0, max=1)\n",
        "          all_outputs.append(outputs.cpu())\n",
        "  all_outputs = torch.cat(all_outputs, dim=0)\n",
        "  return all_outputs\n",
        "\n",
        "valid_model_outs = get_outputs(valid_search, valid_class, valid_out)\n",
        "print(valid_model_outs.shape)"
      ],
      "metadata": {
        "id": "HA6J-KesL2G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image2(searches, outs, outs_pred, index):\n",
        "  plt.clf()\n",
        "  img_search = searches[index]\n",
        "  img_search_np = img_search.numpy()\n",
        "  img_out = outs[index]\n",
        "  img_out_np = img_out.numpy()\n",
        "  img_out_pred = outs_pred[index]\n",
        "  img_out_pred_np = img_out_pred.numpy()\n",
        "  fig, ax = plt.subplots(1, 3, figsize=(9, 9))\n",
        "  ax[0].imshow(img_search_np)\n",
        "  ax[0].set_title('Search Image')\n",
        "  ax[1].imshow(img_out_np, cmap='gray', vmin=0, vmax=1)\n",
        "  ax[1].set_title('Mask Image')\n",
        "  ax[2].imshow(img_out_pred_np, cmap='gray', vmin=0, vmax=1)\n",
        "  ax[2].set_title('Predicted Mask Image')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8fYiq43nL2U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_ind_to_name = {0: 'Water', 1: 'Sand', 2: 'Grass', 3: 'Mountain', 4: 'Snow'}\n",
        "ind = 7 # 0, 2, 3, 7, 8\n",
        "print(class_ind_to_name[valid_class[ind].item()])\n",
        "plot_image2(valid_search, valid_out, valid_model_outs, ind)"
      ],
      "metadata": {
        "id": "z0HrnuM4L2jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "if True:\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/logs\")\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/my_model\")\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "m-pMtlpCL2yk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}