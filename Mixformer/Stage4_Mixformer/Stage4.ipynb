{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ3zpc5yddqM"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning > /dev/null 2>&1\n",
        "!pip install einops > /dev/null 2>&1\n",
        "!pip install timm > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf MixformerFromScratch\n",
        "!git clone https://github.com/reeWorlds/MixformerFromScratch.git\n",
        "!pip install -e \"MixformerFromScratch\"\n",
        "\n",
        "import site\n",
        "site.main()"
      ],
      "metadata": {
        "id": "k6q4hHFFdgIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  import os\n",
        "  os._exit(0)"
      ],
      "metadata": {
        "id": "HFzfqZZVdgRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import seaborn as sns\n",
        "from functools import reduce\n",
        "from operator import mul\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from Mixformer import st4_mxformer"
      ],
      "metadata": {
        "id": "-6I-sV4edga2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#path_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage4_Easy'\n",
        "path_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage4_Hard'"
      ],
      "metadata": {
        "id": "U_O_RHtEdgkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_patches_nums = list(range(40)) # up to 45\n",
        "valid_patches_nums = list(range(40, 45))\n",
        "\n",
        "trn_s, trn_t, trn_ans = None, None, None\n",
        "vld_s, vld_t, vld_ans = None, None, None\n",
        "\n",
        "def get_tensor_by_path(file_path, size, shape, dtype):\n",
        "  mmapped_array = np.memmap(file_path, dtype=dtype, mode='r', shape=(size,))\n",
        "  tensor = torch.from_numpy(mmapped_array)\n",
        "  return tensor.reshape(*shape)\n",
        "\n",
        "def get_data_by_num(path_num):\n",
        "  s_path = os.path.join(path_prefix, f'patch{path_num}_search.bin')\n",
        "  s_shape = (10000, 64, 64, 3)\n",
        "  s = get_tensor_by_path(s_path, reduce(mul, s_shape), s_shape, np.float32)\n",
        "  t_path = os.path.join(path_prefix, f'patch{path_num}_target.bin')\n",
        "  t_shape = (10000, 48, 48, 3)\n",
        "  t = get_tensor_by_path(t_path, reduce(mul, t_shape), t_shape, np.float32)\n",
        "  ans_path = os.path.join(path_prefix, f'patch{path_num}_output.bin')\n",
        "  #ans_shape = (10000, 3)\n",
        "  ans_shape = (10000, 2)\n",
        "  ans = get_tensor_by_path(ans_path, reduce(mul, ans_shape), ans_shape, np.float32)\n",
        "  return s, t, ans\n",
        "\n",
        "def get_data(nums):\n",
        "  list_s, list_t, list_ans = [], [], []\n",
        "  for patch_num in nums:\n",
        "    s, t, ans = get_data_by_num(patch_num)\n",
        "    list_s.append(s)\n",
        "    list_t.append(t)\n",
        "    list_ans.append(ans)\n",
        "    if patch_num % 5 == 0:\n",
        "      print(f'Finished patch_num = {patch_num}')\n",
        "  tensor_s = torch.cat(list_s, dim=0)\n",
        "  tensor_t = torch.cat(list_t, dim=0)\n",
        "  tensor_ans = torch.cat(list_ans, dim=0)\n",
        "  return tensor_s, tensor_t, tensor_ans\n",
        "\n",
        "trn_s, trn_t, trn_ans = get_data(train_patches_nums)\n",
        "vld_s, vld_t, vld_ans = get_data(valid_patches_nums)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(f'train data shapes are s:{trn_s.shape} t:{trn_t.shape} ans:{trn_ans.shape}')\n",
        "print(f'train data shapes are s:{vld_s.shape} t:{vld_t.shape} ans:{vld_ans.shape}')"
      ],
      "metadata": {
        "id": "M5r06YzXdgr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(img_s, img_t, img_ans, idx):\n",
        "  plt.clf()\n",
        "  img_s_np = img_s[idx].numpy()\n",
        "  img_t_np = img_t[idx].numpy()\n",
        "  img_xy_np = img_ans[idx,0:2].numpy()\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
        "  ax[0].imshow(img_s_np)\n",
        "  ax[0].set_title('Search')\n",
        "  ax[1].imshow(img_t_np)\n",
        "  ax[1].set_title('Target')\n",
        "  cx, cy = img_xy_np\n",
        "  pos_x_search = int(cx * 64)\n",
        "  pos_y_search = int(cy * 64)\n",
        "  ax[0].scatter(pos_x_search, pos_y_search, color='red', s=25)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8xXOrkK8dgz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 14\n",
        "plot_image(trn_s, trn_t, trn_ans, idx)"
      ],
      "metadata": {
        "id": "bdN-0cuIdg7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, _s, _t, _ans):\n",
        "        self._s = _s\n",
        "        self._t = _t\n",
        "        self._ans = _ans\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._ans)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self._s[idx], self._t[idx], self._ans[idx]"
      ],
      "metadata": {
        "id": "TkBd-67IdhEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_str = 'medium'"
      ],
      "metadata": {
        "id": "jjbN1ftidhMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def _calc_loss(_pred, _ref):\n",
        "#  _pred_pos, _pred_scale = _pred[:,0:2], _pred[:,2:3]\n",
        "#  _ref_pos, _ref_scale = _ref[:,0:2], _ref[:,2:3]\n",
        "#  loss_pos = F.mse_loss(_pred_pos, _ref_pos)\n",
        "#  loss_scale = F.mse_loss(_pred_scale, _ref_scale)\n",
        "#  loss = loss_pos + 0.1 * loss_scale\n",
        "#  return loss\n",
        "\n",
        "def _calc_loss(_pred, _ref):\n",
        "  pred_pos = _pred[:,0:2]\n",
        "  loss = F.mse_loss(pred_pos, _ref)\n",
        "  return loss\n",
        "\n",
        "class LightningMixFormer(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    config = st4_mxformer.make_mixformer_config(size_str)\n",
        "    self.model = st4_mxformer.MixFormer(config)\n",
        "    self.start_lr = 1e-3\n",
        "    self.lr_gamma = 0.75\n",
        "\n",
        "  def forward(self, _s, _t):\n",
        "    return self.model(_s, _t)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    _s, _t, _m_ref = batch\n",
        "    _m_pred = self.model(_s, _t)\n",
        "    loss =_calc_loss(_m_pred, _m_ref)\n",
        "    self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    _s, _t, _m_ref = batch\n",
        "    _m_pred = self.model(_s, _t)\n",
        "    loss =_calc_loss(_m_pred, _m_ref)\n",
        "    self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.start_lr, weight_decay=1e-6)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=self.lr_gamma)\n",
        "    return {'optimizer': optimizer,\n",
        "            'lr_scheduler': {'scheduler': scheduler, 'interval': 'epoch', 'frequency': 1} }\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = MyDataset(trn_s, trn_t, trn_ans)\n",
        "    return DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    valid_dataset = MyDataset(vld_s, vld_t, vld_ans)\n",
        "    return DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "0Mq6dLqFdhXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainer(max_epochs):\n",
        "  checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath='my_model/',\n",
        "                                        filename='model-{epoch:02d}-{val_loss:.2f}',\n",
        "                                        save_top_k=5, mode='min')\n",
        "  csv_logger = pl_loggers.CSVLogger('logs')\n",
        "  trainer = pl.Trainer(max_epochs=max_epochs,callbacks=[checkpoint_callback], logger=csv_logger)\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "nt7hmR8gdh0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_pretrained = True\n",
        "if load_pretrained == True:\n",
        "  path_pret_pref = '/content/drive/My Drive/Data/DiplomeGenerated/Stage4_Easy'\n",
        "  path_pret = os.path.join(path_pret_pref, f'models/model_{size_str}.ckpt')\n",
        "  model = LightningMixFormer.load_from_checkpoint(path_pret)\n",
        "else:\n",
        "  model = LightningMixFormer()"
      ],
      "metadata": {
        "id": "UMeEGvCWdh_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = get_trainer(10)\n",
        "model.start_lr = 1e-3\n",
        "model.lr_gamma = 0.85\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "id": "uSj3pBq7diLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_checkpoint(\"model.ckpt\")\n",
        "checkpoint_path = os.path.join(path_prefix, f'models/model_{size_str}.ckpt')\n",
        "trainer.save_checkpoint(checkpoint_path)"
      ],
      "metadata": {
        "id": "OMHHX43UdiUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(path_prefix, f'models/model_{size_str}.ckpt')\n",
        "model = LightningMixFormer.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model = model.eval().to('cuda')"
      ],
      "metadata": {
        "id": "WaeNMhksdic6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outputss(searches, targets, anss):\n",
        "  dataset = MyDataset(searches, targets, anss)\n",
        "  data_loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "  all_anss = []\n",
        "  with torch.no_grad():\n",
        "      for batch in data_loader:\n",
        "          _search = batch[0].to('cuda')\n",
        "          _target = batch[1].to('cuda')\n",
        "          ans = model(_search, _target)\n",
        "          ans = ans[:, 0:2]\n",
        "          ans = torch.clamp(ans, min=0, max=1)\n",
        "          all_anss.append(ans.to('cpu').detach())\n",
        "  all_anss = torch.cat(all_anss, dim=0)\n",
        "  return all_anss\n",
        "\n",
        "valid_anss = get_outputss(vld_s, vld_t, vld_ans)\n",
        "print(valid_anss.shape)"
      ],
      "metadata": {
        "id": "k7mbOuiUdilt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cat([valid_anss[0:10], vld_ans[0:10]], dim=1))"
      ],
      "metadata": {
        "id": "dggQZN0Hdiv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = _calc_loss(valid_anss, vld_ans)\n",
        "print(loss)\n",
        "#print(f\"ref loss = {_calc_loss(torch.zeros(vld_ans.shape[0], 3) + 0.5, vld_ans)}\")\n",
        "print(f\"ref loss = {_calc_loss(torch.zeros(vld_ans.shape[0], 2) + 0.5, vld_ans)}\")"
      ],
      "metadata": {
        "id": "vf0Ufx4odi7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image2(img_s, img_t, img_ans, img_ans_p, idx):\n",
        "  plt.clf()\n",
        "  img_s_np = img_s[idx].numpy()\n",
        "  img_t_np = img_t[idx].numpy()\n",
        "  img_xy_np = img_ans[idx,0:2].numpy()\n",
        "  img_xy_p_np = img_ans_p[idx,0:2].numpy()\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
        "  ax[0].imshow(img_s_np)\n",
        "  ax[0].set_title('Search')\n",
        "  ax[1].imshow(img_t_np)\n",
        "  ax[1].set_title('Target')\n",
        "  cx, cy = img_xy_np\n",
        "  pos_x_search = int(cx * 64)\n",
        "  pos_y_search = int(cy * 64)\n",
        "  ax[0].scatter(pos_x_search, pos_y_search, color='red', s=15)\n",
        "  cx, cy = img_xy_p_np\n",
        "  pos_x_search = int(cx * 64)\n",
        "  pos_y_search = int(cy * 64)\n",
        "  ax[0].scatter(pos_x_search, pos_y_search, color='yellow', s=10)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "G2XABVFdkQ_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 15\n",
        "plot_image2(vld_s, vld_t, vld_ans, valid_anss, idx)"
      ],
      "metadata": {
        "id": "0-g8tJ4ukTJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_exceeding_distances(vld_ans, valid_anss, threshold):\n",
        "  distances = torch.norm(vld_ans - valid_anss, dim=1, p=2)\n",
        "  exceeding = distances > threshold\n",
        "  count = torch.sum(exceeding.int())\n",
        "  return count\n",
        "cnt_bad = count_exceeding_distances(vld_ans, valid_anss, 0.1)\n",
        "cnt_good = vld_ans.shape[0] - cnt_bad\n",
        "print(f\"% of good is {cnt_good / vld_ans.shape[0] * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "uP8-QQnwur94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "if True:\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/logs\")\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/my_model\")\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "zc0URpfFdjPu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}