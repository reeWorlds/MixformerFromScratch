{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37MW6nfekDms"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning > /dev/null 2>&1\n",
        "!pip install einops > /dev/null 2>&1\n",
        "!pip install timm > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf MixformerFromScratch\n",
        "!git clone https://github.com/reeWorlds/MixformerFromScratch.git\n",
        "!pip install -e \"MixformerFromScratch\"\n",
        "\n",
        "import site\n",
        "site.main()"
      ],
      "metadata": {
        "id": "Ytdmx8QbkKY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  import os\n",
        "  os._exit(0)"
      ],
      "metadata": {
        "id": "HUcOY2rmkKk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from Mixformer import st2_ae"
      ],
      "metadata": {
        "id": "Yy23j8OEkKs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage2_AE'"
      ],
      "metadata": {
        "id": "GIROhAEOkK1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder_path = data_prefix\n",
        "\n",
        "train_patches_nums = list(range(21)) # up to 21\n",
        "\n",
        "train_data = None, None\n",
        "\n",
        "def get_tensor_by_path(file_path, size, shape, dtype):\n",
        "  mmapped_array = np.memmap(file_path, dtype=dtype, mode='r', shape=(size,))\n",
        "  tensor = torch.from_numpy(mmapped_array)\n",
        "  return tensor.reshape(*shape)\n",
        "\n",
        "def get_data_by_num(path_num):\n",
        "  data_path = os.path.join(data_folder_path, f'patch{path_num}_64x64.bin')\n",
        "  data_size = 10000 * 64 * 64 * 3\n",
        "  data_tensor = get_tensor_by_path(data_path, data_size, (10000, 64, 64, 3), np.float32)\n",
        "  return data_tensor\n",
        "list_data = []\n",
        "\n",
        "for patch_num in train_patches_nums:\n",
        "  d = get_data_by_num(patch_num)\n",
        "  list_data.append(d)\n",
        "  if patch_num % 4 == 0:\n",
        "    print(f'Finished patch_num = {patch_num}')\n",
        "\n",
        "train_data = torch.cat(list_data, dim=0)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(f'train data shapes are d:{train_data.shape}')"
      ],
      "metadata": {
        "id": "SYKACBOU7nEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(data, index):\n",
        "  plt.clf()\n",
        "  img_data = data[index]\n",
        "  img_data_np = img_data.numpy()\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
        "  ax.imshow(img_data_np)\n",
        "  ax.set_title('Image')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "XoKzzyU8kLEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 0\n",
        "plot_image(train_data, ind)"
      ],
      "metadata": {
        "id": "MCYsMVg9kLSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, _data):\n",
        "        self._data = _data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self._data[idx]"
      ],
      "metadata": {
        "id": "wPH9e29bkLtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningMixFormer(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    config = st2_ae.ConfigGeneration.make_ae_config()\n",
        "    self.model = st2_ae.Autoencoder(config)\n",
        "    self.start_lr = 1e-3\n",
        "    self.lr_gamma = 0.86\n",
        "\n",
        "  def forward(self, _data):\n",
        "    return self.model(_data)\n",
        "\n",
        "  def get_loss(self, _data, _data_pred):\n",
        "    #loss = F.binary_cross_entropy(_data_pred, _data)\n",
        "    loss = F.mse_loss(_data_pred, _data)\n",
        "    return loss\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    data_out = self.model(batch)\n",
        "    loss = self.get_loss(batch, data_out)\n",
        "    self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.start_lr, weight_decay=1e-6)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=self.lr_gamma)\n",
        "    return {'optimizer': optimizer,\n",
        "            'lr_scheduler': {'scheduler': scheduler, 'interval': 'epoch', 'frequency': 1} }\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = MyDataset(train_data)\n",
        "    return torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "oasKgfSykL6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainer(max_epochs):\n",
        "  checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath='my_model/',\n",
        "                                        filename='model-{epoch:02d}-{val_loss:.2f}',\n",
        "                                        save_top_k=5, mode='min')\n",
        "  csv_logger = pl_loggers.CSVLogger('logs')\n",
        "  trainer = pl.Trainer(max_epochs=max_epochs,callbacks=[checkpoint_callback],\n",
        "                       logger=csv_logger)\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "gdmZ5JiTkMNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightningMixFormer()"
      ],
      "metadata": {
        "id": "WO5RK59UkMv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = get_trainer(12)\n",
        "model.start_lr = 1e-3\n",
        "model.lr_gamma = 0.75\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "id": "oc_AtG6fkM5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "model_v = 1\n",
        "\n",
        "trainer.save_checkpoint(\"model.ckpt\")\n",
        "model_checkpoint_path = os.path.join(data_prefix, f'models/model_v{model_v}.ckpt')\n",
        "trainer.save_checkpoint(model_checkpoint_path)"
      ],
      "metadata": {
        "id": "Cc5PoaKCkNC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(data_prefix, f'models/model_v{model_v}.ckpt')\n",
        "model = LightningMixFormer.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model.eval()\n",
        "model.to('cuda')\n",
        "pass"
      ],
      "metadata": {
        "id": "cQ5tH5ExkNLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outputs(datas):\n",
        "  dataset = MyDataset(datas)\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False, num_workers=2)\n",
        "  all_out_data = []\n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      _data = batch.to('cuda')\n",
        "      out_d = model(_data)\n",
        "      all_out_data.append(out_d.cpu())\n",
        "  all_out_data = torch.cat(all_out_data, dim=0)\n",
        "  return all_out_data\n",
        "\n",
        "train_data_outs = get_outputs(train_data[0:1000])"
      ],
      "metadata": {
        "id": "sXj4JvarkNXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image2(d, d_out, index):\n",
        "  plt.clf()\n",
        "  img_d_np = d[index].numpy()\n",
        "  img_d_out_np = d_out[index].clamp(0, 1).numpy()\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(6, 6))\n",
        "  ax[0].imshow(img_d_np)\n",
        "  ax[0].set_title('Image')\n",
        "  ax[1].imshow(img_d_out_np)\n",
        "  ax[1].set_title('Image_out')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "TjqF1TBTkNi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 5\n",
        "plot_image2(train_data, train_data_outs, ind)"
      ],
      "metadata": {
        "id": "Ggx1AaoAkNu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "if True:\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/logs\")\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/my_model\")\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "XdL77umTeByV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}