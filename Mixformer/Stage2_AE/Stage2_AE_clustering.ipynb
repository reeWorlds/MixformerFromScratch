{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Embeddings Generation**"
      ],
      "metadata": {
        "id": "c7ecnQOmEqm9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTFODWvuBVNl"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning > /dev/null 2>&1\n",
        "!pip install einops > /dev/null 2>&1\n",
        "!pip install timm > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf MixformerFromScratch\n",
        "!git clone https://github.com/reeWorlds/MixformerFromScratch.git\n",
        "!pip install -e \"MixformerFromScratch\"\n",
        "\n",
        "import site\n",
        "site.main()"
      ],
      "metadata": {
        "id": "tzON_pX-BZOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  import os\n",
        "  os._exit(0)"
      ],
      "metadata": {
        "id": "tHrd3H3pIT8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from einops import rearrange\n",
        "\n",
        "from Mixformer import st2_ae"
      ],
      "metadata": {
        "id": "CzZW16OsBZsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage2'"
      ],
      "metadata": {
        "id": "Ec70dMVRBqnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, _data):\n",
        "        self._data = _data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self._data[idx]"
      ],
      "metadata": {
        "id": "Pya-M3RaHOzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningMixFormer(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    config = st2_ae.ConfigGeneration.make_ae_config()\n",
        "    self.model = st2_ae.Autoencoder(config)\n",
        "\n",
        "  def forward(self, _data):\n",
        "    return self.model.forward_encoder(_data)"
      ],
      "metadata": {
        "id": "GNDdo8MEFI_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(data_prefix, f'models/model_ae.ckpt')\n",
        "model = LightningMixFormer.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model = model.eval().to('cuda')"
      ],
      "metadata": {
        "id": "DF1QUbWhFVfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_patches_nums = list(range(21)) # up to 21\n",
        "\n",
        "def get_tensor_by_path(file_path, size, shape, dtype):\n",
        "  mmapped_array = np.memmap(file_path, dtype=dtype, mode='r', shape=(size,))\n",
        "  tensor = torch.from_numpy(mmapped_array)\n",
        "  return tensor.reshape(*shape)\n",
        "\n",
        "def get_data_by_num(path_num):\n",
        "  data_path = os.path.join(data_prefix, f'patch{path_num}_64x64.bin')\n",
        "  data_size = 10000 * 64 * 64 * 3\n",
        "  data_tensor = get_tensor_by_path(data_path, data_size, (10000, 64, 64, 3), np.float32)\n",
        "  return data_tensor\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "for patch_num in train_patches_nums:\n",
        "  d = get_data_by_num(patch_num)\n",
        "  dataset = MyDataset(d)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "  outputs = []\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to(device)\n",
        "    output = model(batch).to('cpu')\n",
        "    outputs.append(output.clone().detach())\n",
        "  outputs = torch.cat(outputs, dim=0)\n",
        "  patch_path = os.path.join(data_prefix, f\"patch{patch_num}_embd.pt\")\n",
        "  torch.save(outputs, patch_path)\n",
        "  print(f\"patch={patch_num} has shape {outputs.shape}\")"
      ],
      "metadata": {
        "id": "Kyeh0OkXBsB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering**"
      ],
      "metadata": {
        "id": "trsvylO2QNY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "TuHaUg7yQNGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage2'"
      ],
      "metadata": {
        "id": "a-j3EsLhQ08V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_patches_nums = list(range(21)) # up to 21\n",
        "\n",
        "list_d = []\n",
        "\n",
        "for patch_num in train_patches_nums:\n",
        "  d_path = os.path.join(data_prefix, f'patch{patch_num}_embd.pt')\n",
        "  d = torch.load(d_path)\n",
        "  list_d.append(d)\n",
        "  if patch_num % 5 == 0:\n",
        "    print(f\"loaded patch={patch_num}\")\n",
        "\n",
        "data = torch.cat(list_d, dim=0).numpy()\n",
        "print(f\"data shape is {data.shape}\")"
      ],
      "metadata": {
        "id": "4WAjkBlgQ1IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 20\n",
        "best_score = 0\n",
        "best_labels = None\n",
        "for rs in range(250):\n",
        "  kmeans = KMeans(n_clusters=n_clusters, n_init=1, random_state=rs)\n",
        "  kmeans.fit(data)\n",
        "  t_labels = kmeans.labels_\n",
        "  t_cluster_counts = np.bincount(t_labels)\n",
        "  t_score = min(t_cluster_counts)\n",
        "  if t_score > best_score:\n",
        "    best_score = t_score\n",
        "    best_labels = t_labels\n",
        "    print(f\"New best score {best_score} at rs = {rs}\")"
      ],
      "metadata": {
        "id": "tq1IFMLvysB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 20\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=1, random_state=146)\n",
        "kmeans.fit(data)\n",
        "labels = kmeans.labels_"
      ],
      "metadata": {
        "id": "NchRdGYzQ1TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_counts = np.bincount(labels)\n",
        "print(cluster_counts)"
      ],
      "metadata": {
        "id": "dou4Gd8IQ1vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_pt = torch.tensor(labels)\n",
        "for patch_num in range(21):\n",
        "  l = 10000 * patch_num\n",
        "  r = 10000 * (1 + patch_num)\n",
        "  sub_data = labels_pt[l:r].to(dtype=torch.int64)\n",
        "  sub_data_path = os.path.join(data_prefix, f\"patch{patch_num}_labels.pt\")\n",
        "  torch.save(sub_data, sub_data_path)"
      ],
      "metadata": {
        "id": "kwrJQzJCQ1-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot pictures in cluster**"
      ],
      "metadata": {
        "id": "FfWiYBnkZNk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dOpEqdxXneOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage2'"
      ],
      "metadata": {
        "id": "rRjL9K4EZNBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tensor_by_path(file_path, size, shape, dtype):\n",
        "  mmapped_array = np.memmap(file_path, dtype=dtype, mode='r', shape=(size,))\n",
        "  tensor = torch.from_numpy(mmapped_array)\n",
        "  return tensor.reshape(*shape)\n",
        "\n",
        "def get_data():\n",
        "  img_path = os.path.join(data_prefix, f'patch0_64x64.bin')\n",
        "  img_size = 10000 * 64 * 64 * 3\n",
        "  img_tensor = get_tensor_by_path(img_path, img_size, (10000, 64, 64, 3), np.float32)\n",
        "  lbl_path = os.path.join(data_prefix, f'patch0_labels.pt')\n",
        "  lbl_tensor = torch.load(lbl_path)\n",
        "  return img_tensor, lbl_tensor\n",
        "\n",
        "data_images, data_labels = get_data()\n",
        "\n",
        "print(f'images.shape = {data_images.shape}')\n",
        "print(f'labels.shape = {data_labels.shape}')"
      ],
      "metadata": {
        "id": "c5nHk7bqnMhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_idx = {i: [] for i in range(20)}\n",
        "for i in range(data_images.shape[0]):\n",
        "  list_idx[data_labels[i].item()].append(i)"
      ],
      "metadata": {
        "id": "NR9x2XGdnMsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(_idxs):\n",
        "  plt.clf()\n",
        "  n = int(math.sqrt(len(_idxs)))\n",
        "  images = [data_images[index].numpy() for index in _idxs]\n",
        "  fig, ax = plt.subplots(n, n, figsize=(6, 6))\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      ax[i, j].imshow(images[i * n + j])\n",
        "      ax[i, j].set_title(f'Image {_idxs[i * n + j]}')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tIY5Kun_p2pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = list_idx[5][0:16]\n",
        "plot_images(idxs)"
      ],
      "metadata": {
        "id": "wB4aNQuLnM28"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}