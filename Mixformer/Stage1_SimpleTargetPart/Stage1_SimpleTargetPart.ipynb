{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H10hmwCPOtNx"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning > /dev/null 2>&1\n",
        "!pip install einops > /dev/null 2>&1\n",
        "!pip install timm > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf MixformerFromScratch\n",
        "!git clone https://github.com/reeWorlds/MixformerFromScratch.git\n",
        "!pip install -e \"MixformerFromScratch\"\n",
        "\n",
        "import site\n",
        "site.main()"
      ],
      "metadata": {
        "id": "CSqT-jXruEHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  import os\n",
        "  os._exit(0)"
      ],
      "metadata": {
        "id": "QIv4fvpH7Jzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from Mixformer import st1_target"
      ],
      "metadata": {
        "id": "o2s3BowCO6f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage1_SimpleTargetPart'"
      ],
      "metadata": {
        "id": "3u5SGu4XO6sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder_path = data_prefix\n",
        "\n",
        "train_patches_nums = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "valid_path_num = 10\n",
        "\n",
        "train_target, train_out = None, None\n",
        "valid_target, valid_out = None, None\n",
        "\n",
        "def get_tensor_by_path(file_path, size, shape):\n",
        "  dtype = np.float32\n",
        "  mmapped_array = np.memmap(file_path, dtype=dtype, mode='r', shape=(size,))\n",
        "  tensor = torch.from_numpy(mmapped_array)\n",
        "  return tensor.reshape(*shape)\n",
        "\n",
        "def get_data_by_num(path_num):\n",
        "  target_path = os.path.join(data_folder_path, f'patch{path_num}_target.bin')\n",
        "  target_size = 10000 * 48 * 48 * 3\n",
        "  target_tensor = get_tensor_by_path(target_path, target_size, (10000, 48, 48, 3))\n",
        "  out_path = os.path.join(data_folder_path, f'patch{path_num}_output.bin')\n",
        "  out_size = 10000 * 5\n",
        "  out_tensor = get_tensor_by_path(out_path, out_size, (10000, 5))\n",
        "  return target_tensor, out_tensor\n",
        "\n",
        "for patch_num in train_patches_nums:\n",
        "  t, o = get_data_by_num(patch_num)\n",
        "  if train_target == None:\n",
        "    train_target, train_out = t, o\n",
        "  else:\n",
        "    train_target = torch.cat((train_target, t), dim=0)\n",
        "    train_out = torch.cat((train_out, o), dim=0)\n",
        "  print(f'Finished patch_num = {patch_num}')\n",
        "\n",
        "valid_target, valid_out = get_data_by_num(valid_path_num)\n",
        "gc.collect()\n",
        "\n",
        "print(f'train data shapes are t:{train_target.shape}, o:{train_out.shape}')\n",
        "print(f'valid data shapes are t:{valid_target.shape}, o:{valid_out.shape}')"
      ],
      "metadata": {
        "id": "mT7jdLzbO624"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(targets, index):\n",
        "  plt.clf()\n",
        "  img_target = targets[index]\n",
        "  img_target_np = img_target.numpy()\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
        "  ax.imshow(img_target_np)\n",
        "  ax.set_title('Target Image')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "XbbkX6d7O7Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 1\n",
        "print(train_out[ind])\n",
        "try:\n",
        "  print(train_model_outs[ind])\n",
        "except:\n",
        "  pass\n",
        "plot_image(train_target, ind)"
      ],
      "metadata": {
        "id": "_wKhCIARO7Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, target, out):\n",
        "        self.target = target\n",
        "        self.out = out\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.target[idx], self.out[idx]"
      ],
      "metadata": {
        "id": "4w-r2fV8QL3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningMixFormer(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        config = st1_target.make_mixformer_config(\"medium\")\n",
        "        self.model = st1_target.MixFormer(config)\n",
        "        self.train_dataset = MyDataset(train_target, train_out)\n",
        "        self.valid_dataset = MyDataset(valid_target, valid_out)\n",
        "\n",
        "    def forward(self, target):\n",
        "        return self.model(target)\n",
        "\n",
        "    def get_loss(self, out_pred, out):\n",
        "        loss = torch.nn.functional.mse_loss(out_pred, out)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        target, out = batch\n",
        "        out_pred = self.model(target)\n",
        "        loss = self.get_loss(out_pred, out)\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        target, out = batch\n",
        "        out_pred = self.model(target)\n",
        "        loss = self.get_loss(out_pred, out)\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': scheduler,\n",
        "                'interval': 'epoch',\n",
        "                'frequency': 1\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.train_dataset, batch_size=512, shuffle=True, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.valid_dataset, batch_size=1024, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "e27AJLRbQMAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    dirpath='my_model/',\n",
        "    filename='model-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=10,\n",
        "    mode='min',\n",
        ")\n",
        "csv_logger = pl_loggers.CSVLogger('logs')\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=6,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    logger=csv_logger\n",
        ")"
      ],
      "metadata": {
        "id": "qgm0Q9vVQMNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightningMixFormer()"
      ],
      "metadata": {
        "id": "KLHjs5cpY4T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model)"
      ],
      "metadata": {
        "id": "TdtNKcUxY4gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "model_v = 3\n",
        "\n",
        "#source_path = '/content/logs/lightning_logs/version_0/metrics.csv'\n",
        "#dest_path = os.path.join(data_prefix, f'models/logs_medium_v{model_v}.csv')\n",
        "#shutil.copyfile(source_path, dest_path)\n",
        "\n",
        "trainer.save_checkpoint(\"model.ckpt\")\n",
        "model_checkpoint_path = os.path.join(data_prefix, f'models/model_medium_v{model_v}.ckpt')\n",
        "trainer.save_checkpoint(model_checkpoint_path)"
      ],
      "metadata": {
        "id": "FT27sCKwY4rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(data_prefix, f'models/model_medium_v{model_v}.ckpt')\n",
        "model = LightningMixFormer.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model = model.eval().to('cuda')"
      ],
      "metadata": {
        "id": "U-ki9SN37mL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outputs(targets, outs):\n",
        "  dataset = MyDataset(targets, outs)\n",
        "  data_loader = torch.utils.data.DataLoader(dataset, batch_size=512, shuffle=False, num_workers=2)\n",
        "  all_outputs = []\n",
        "  with torch.no_grad():\n",
        "      for batch in data_loader:\n",
        "          target = batch[0].to('cuda')\n",
        "          outputs = model(target)\n",
        "          all_outputs.append(outputs.cpu())\n",
        "  all_outputs = torch.cat(all_outputs, dim=0)\n",
        "  return all_outputs\n",
        "\n",
        "train_model_outs = get_outputs(train_target, train_out)\n",
        "valid_model_outs = get_outputs(valid_target, valid_out)\n",
        "print(train_model_outs.shape)\n",
        "print(valid_model_outs.shape)"
      ],
      "metadata": {
        "id": "ciiYdv2D7meJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_average_score(out):\n",
        "  avg_values = out.mean(dim=0)\n",
        "  out_avg = avg_values.repeat(out.shape[0], 1)\n",
        "  loss = torch.nn.functional.mse_loss(out_avg, out)\n",
        "  return loss # default loss is about 0.01\n",
        "\n",
        "print(f'Validation average score = {get_average_score(valid_out)}')\n",
        "print(f'Train average score = {get_average_score(train_out)}')"
      ],
      "metadata": {
        "id": "8HBegCdZ_kAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_by_result(out, out2, ind):\n",
        "  print(f\"{out[ind,0]:.4f} {out[ind,1]:.4f} {out[ind,2]:.4f} {out[ind,3]:.4f} {out[ind,4]:.4f}\")\n",
        "  print(f\"{out2[ind,0]:.4f} {out2[ind,1]:.4f} {out2[ind,2]:.4f} {out2[ind,3]:.4f} {out2[ind,4]:.4f}\")\n",
        "  print()\n",
        "\n",
        "compare_by_result(valid_out, valid_model_outs, 0)\n",
        "compare_by_result(valid_out, valid_model_outs, 1)\n",
        "compare_by_result(valid_out, valid_model_outs, 2)\n"
      ],
      "metadata": {
        "id": "yWwql8kn_kT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "if True:\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/logs\")\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/my_model\")\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "8ziY_WRR7msH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}