{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghFWUROw3wCu"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning > /dev/null 2>&1\n",
        "!pip install einops > /dev/null 2>&1\n",
        "!pip install timm > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf MixformerFromScratch\n",
        "!git clone https://github.com/reeWorlds/MixformerFromScratch.git\n",
        "!pip install -e \"MixformerFromScratch\"\n",
        "\n",
        "import site\n",
        "site.main()"
      ],
      "metadata": {
        "id": "hoPNeD2j3zEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "  import os\n",
        "  os._exit(0)"
      ],
      "metadata": {
        "id": "6BKxieYG3zOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import seaborn as sns\n",
        "from functools import reduce\n",
        "from operator import mul\n",
        "from einops import rearrange\n",
        "from einops.layers.torch import Rearrange\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from Mixformer import st2_xformer"
      ],
      "metadata": {
        "id": "My3tbqpt3zXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage2'"
      ],
      "metadata": {
        "id": "8la0B9f23zeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder_path = data_prefix\n",
        "\n",
        "train_patches_nums = list(range(20)) # up to 20\n",
        "valid_pathch_num = 20\n",
        "\n",
        "trn_s, trn_t, trn_s_stats, trn_t_stats, trn_types, trn_infos = None, None, None, None, None, None\n",
        "vld_s, vld_t, vld_s_stats, vld_t_stats, vld_types, vld_infos = None, None, None, None, None, None\n",
        "\n",
        "def get_tensor_by_path(file_path, size, shape, dtype):\n",
        "  mmapped_array = np.memmap(file_path, dtype=dtype, mode='r', shape=(size,))\n",
        "  tensor = torch.from_numpy(mmapped_array)\n",
        "  return tensor.reshape(*shape)\n",
        "\n",
        "def get_data_by_num(path_num):\n",
        "  s_path = os.path.join(data_folder_path, f'patch{path_num}_64x64.bin')\n",
        "  s_shape = (10000, 64, 64, 3)\n",
        "  s = get_tensor_by_path(s_path, reduce(mul, s_shape), s_shape, np.float32)\n",
        "  t_path = os.path.join(data_folder_path, f'patch{path_num}_48x48.bin')\n",
        "  t_shape = (10000, 48, 48, 3)\n",
        "  t = get_tensor_by_path(t_path, reduce(mul, t_shape), t_shape, np.float32)\n",
        "  s_stats_path = os.path.join(data_folder_path, f'patch{path_num}_64x64_stats.bin')\n",
        "  s_stats_shape = (10000, 8, 8, 5)\n",
        "  s_stats = get_tensor_by_path(s_stats_path, reduce(mul, s_stats_shape), s_stats_shape, np.float32)\n",
        "  t_stats_path = os.path.join(data_folder_path, f'patch{path_num}_48x48_stats.bin')\n",
        "  t_stats_shape = (10000, 6, 6, 5)\n",
        "  t_stats = get_tensor_by_path(t_stats_path, reduce(mul, t_stats_shape), t_stats_shape, np.float32)\n",
        "  labels_path = os.path.join(data_folder_path, f'patch{path_num}_labels.pt')\n",
        "  labels = torch.load(labels_path)\n",
        "  types = F.one_hot(labels, 20).float()\n",
        "  infos_path = os.path.join(data_folder_path, f'patch{path_num}_info.bin')\n",
        "  infos_shape = (10000, 3)\n",
        "  infos = get_tensor_by_path(infos_path, reduce(mul, infos_shape), infos_shape, np.float32)\n",
        "  return s, t, s_stats, t_stats, types, infos\n",
        "\n",
        "list_s, list_t, list_s_stats, list_t_stats, list_types, list_infos = [], [], [], [], [], []\n",
        "\n",
        "for patch_num in train_patches_nums:\n",
        "  s, t, s_stats, t_stats, types, infos = get_data_by_num(patch_num)\n",
        "  list_s.append(s)\n",
        "  list_t.append(t)\n",
        "  list_s_stats.append(s_stats)\n",
        "  list_t_stats.append(t_stats)\n",
        "  list_types.append(types)\n",
        "  list_infos.append(infos)\n",
        "  if patch_num % 4 == 0:\n",
        "    print(f'Finished patch_num = {patch_num}')\n",
        "\n",
        "trn_s = torch.cat(list_s, dim=0)\n",
        "trn_t = torch.cat(list_t, dim=0)\n",
        "trn_s_stats = torch.cat(list_s_stats, dim=0)\n",
        "trn_t_stats = torch.cat(list_t_stats, dim=0)\n",
        "trn_types = torch.cat(list_types, dim=0)\n",
        "trn_infos = torch.cat(list_infos, dim=0)\n",
        "\n",
        "vld_s, vld_t, vld_s_stats, vld_t_stats, vld_types, vld_infos = get_data_by_num(valid_pathch_num)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(f'train data shapes are s:{trn_s.shape} t:{trn_t.shape} s_s:{trn_s_stats.shape} \\n t_s:{trn_t_stats.shape} tp:{trn_types.shape} inf:{trn_infos.shape}')\n",
        "print(f'train data shapes are s:{vld_s.shape} t:{vld_t.shape} s_s:{vld_s_stats.shape} \\n t_s:{vld_t_stats.shape} tp:{vld_types.shape} inf:{vld_infos.shape}')"
      ],
      "metadata": {
        "id": "gn4eBMma3zuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_names = ['Water', 'Sand', 'Grass', 'Hill', 'Mountain']\n",
        "def plot_image(img, msk, idx):\n",
        "  plt.clf()\n",
        "  img_np = img[idx].numpy()\n",
        "  fig, ax = plt.subplots(1, 6, figsize=(10, 2))\n",
        "  ax[0].imshow(img_np)\n",
        "  ax[0].set_title('Image')\n",
        "  for i in range(5):\n",
        "    ax[1 + i].imshow(msk[idx,:,:,i].numpy())\n",
        "    ax[1 + i].set_title(map_names[i])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "09XY0B9g3z52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 5\n",
        "print(f'type = {torch.argmax(trn_types[idx])}')\n",
        "print(f'info = {trn_infos[idx]}')\n",
        "plot_image(trn_s, trn_s_stats, idx)"
      ],
      "metadata": {
        "id": "Lp-ldgL-30F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, _s, _t, _s_stats, _t_stats, _types, _infos):\n",
        "        self._s = _s\n",
        "        self._t = _t\n",
        "        self._s_stats = _s_stats\n",
        "        self._t_stats = _t_stats\n",
        "        self._types = _types\n",
        "        self._infos = _infos\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._s)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self._s[idx], self._t[idx]), (self._s_stats[idx], self._t_stats[idx], self._types[idx], self._infos[idx])"
      ],
      "metadata": {
        "id": "mXFgZu8v30S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats_loss(pred, ref):\n",
        "  return F.mse_loss(pred, ref)\n",
        "\n",
        "def get_types_loss(pred, ref):\n",
        "  return F.binary_cross_entropy(pred, ref)\n",
        "\n",
        "def get_infos_loss(pred, ref):\n",
        "  loss_scale = F.mse_loss(pred[:,0], ref[:,0])\n",
        "  loss_pers = F.mse_loss(pred[:,1], ref[:,1])\n",
        "  loss_lacu = F.mse_loss(pred[:,2], ref[:,2])\n",
        "  loss_sum = (loss_scale + loss_pers + loss_lacu) / 3.0\n",
        "  return loss_sum\n",
        "\n",
        "def get_full_loss(pred, ref):\n",
        "  p_stats, p_types, p_infos = pred\n",
        "  r_stats, t_types, r_infos = ref\n",
        "  loss_stats = get_stats_loss(p_stats, r_stats)\n",
        "  loss_types = get_types_loss(p_types, t_types)\n",
        "  loss_infos = get_infos_loss(p_infos, r_infos)\n",
        "  loss = 2.0 * loss_stats + 0.5 * loss_types + 0.1 * loss_infos\n",
        "  return loss\n",
        "\n",
        "class LightningTransfromer(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    config = st2_xformer.ConfigGeneration.make_transformer_config('large')\n",
        "    self.model = st2_xformer.Transformer(config)\n",
        "    self.start_lr = 1e-3\n",
        "    self.lr_gamma = 0.75\n",
        "\n",
        "  def forward(self, _d):\n",
        "    return self.model(_d)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    data, outs = batch # (_s, _t) (_s_stats, _t_stats, _types, _infos)\n",
        "    s_preds = self.model(data[0])\n",
        "    t_preds = self.model(data[1])\n",
        "    loss_s = get_full_loss(s_preds, (outs[0], outs[2], outs[3]))\n",
        "    loss_t = get_full_loss(t_preds, (outs[1], outs[2], outs[3]))\n",
        "    loss = loss_s * 1.0 + loss_t * 1.0\n",
        "    self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    data, outs = batch # (_s, _t) (_s_stats, _t_stats, _types, _infos)\n",
        "    s_preds = self.model(data[0])\n",
        "    t_preds = self.model(data[1])\n",
        "    loss_s = get_full_loss(s_preds, (outs[0], outs[2], outs[3]))\n",
        "    loss_t = get_full_loss(t_preds, (outs[1], outs[2], outs[3]))\n",
        "    loss = loss_s * 1.0 + loss_t * 1.0\n",
        "    self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.start_lr, weight_decay=1e-6)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=self.lr_gamma)\n",
        "    return {'optimizer': optimizer,\n",
        "            'lr_scheduler': {'scheduler': scheduler, 'interval': 'epoch', 'frequency': 1} }\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = MyDataset(trn_s, trn_t, trn_s_stats, trn_t_stats, trn_types, trn_infos)\n",
        "    return DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    valid_dataset = MyDataset(vld_s, vld_t, vld_s_stats, vld_t_stats, vld_types, vld_infos)\n",
        "    return DataLoader(valid_dataset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "McE-zHLz30gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainer(max_epochs):\n",
        "  checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath='my_model/',\n",
        "                                        filename='model-{epoch:02d}-{val_loss:.2f}',\n",
        "                                        save_top_k=5, mode='min')\n",
        "  csv_logger = pl_loggers.CSVLogger('logs')\n",
        "  trainer = pl.Trainer(max_epochs=max_epochs,callbacks=[checkpoint_callback],\n",
        "                       logger=csv_logger)\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "yg7E9Dx130sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightningTransfromer()"
      ],
      "metadata": {
        "id": "2Q0R3QTfD53c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = get_trainer(10)\n",
        "model.start_lr = 1e-3\n",
        "model.lr_gamma = 0.75\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "id": "LLqlTiPMD6CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "model_prefix = '/content/drive/My Drive/Data/DiplomeGenerated/Stage2'\n",
        "\n",
        "trainer.save_checkpoint(\"model.ckpt\")\n",
        "checkpoint_path = os.path.join(model_prefix, f'models/model_large.ckpt')\n",
        "trainer.save_checkpoint(checkpoint_path)"
      ],
      "metadata": {
        "id": "0sasPIiWD6LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(model_prefix, f'models/model_large.ckpt')\n",
        "model = LightningTransfromer.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
        "model = model.eval().to('cuda')"
      ],
      "metadata": {
        "id": "XNFLTPSGD6Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_outs(images):\n",
        "  outs = []\n",
        "  dataloader = DataLoader(images, batch_size=128, shuffle=False, num_workers=2)\n",
        "  for batch in dataloader:\n",
        "    batch = batch.to('cuda')\n",
        "    out = model(batch)\n",
        "    outs.append([o.detach().to('cpu') for o in out])\n",
        "  all_stats = torch.cat([o[0] for o in outs], dim=0)\n",
        "  all_types = torch.cat([o[1] for o in outs], dim=0)\n",
        "  all_infos = torch.cat([o[2] for o in outs], dim=0)\n",
        "  return (all_stats, all_types, all_infos)"
      ],
      "metadata": {
        "id": "oFphmKFbyDmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vld_stats_o, vld_types_o, vld_infos_o = get_outs(vld_s)"
      ],
      "metadata": {
        "id": "NNqssqayz16S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image2(img, msk, msk_ref, idx):\n",
        "  plt.clf()\n",
        "  img_np = img[idx].numpy()\n",
        "  fig, ax = plt.subplots(3, 5, figsize=(10, 6))\n",
        "  ax[0, 2].imshow(img_np)\n",
        "  ax[0, 2].set_title('Image')\n",
        "  for i in range(5):\n",
        "    ax[1, i].imshow(msk[idx,:,:,i].numpy())\n",
        "    ax[1, i].set_title(map_names[i])\n",
        "    ax[2, i].imshow(msk_ref[idx,:,:,i].numpy())\n",
        "    ax[2, i].set_title(map_names[i])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "HIpRm8Tk5j1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "print(f'type = {torch.argmax(vld_types[idx])}')\n",
        "print(f'info = {vld_infos[idx]}')\n",
        "plot_image2(vld_s, vld_s_stats, vld_stats_o, idx)"
      ],
      "metadata": {
        "id": "_pMKBkhE5kGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_loss = get_stats_loss(vld_stats_o, vld_s_stats).item()\n",
        "print(f\"stats_loss = {stats_loss}\")"
      ],
      "metadata": {
        "id": "wxjUKaN3DebL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_types_accuracy(pred_types, ref_types):\n",
        "  cnt_all = len(pred_types)\n",
        "  pred_idx = torch.argmax(pred_types, dim=-1)\n",
        "  ref_idx = torch.argmax(ref_types, dim=-1)\n",
        "  cnt_good = torch.sum(torch.eq(pred_idx, ref_idx).int())\n",
        "  return cnt_good, cnt_all\n",
        "cnt_good, cnt_all = get_types_accuracy(vld_types_o, vld_types)\n",
        "print(f\"good = {cnt_good} out of all = {cnt_all}\")\n",
        "print(f\"% good = {cnt_good/cnt_all * 100}\")\n",
        "types_loss = get_types_loss(vld_types_o, vld_types).item()\n",
        "print(f\"types_loss = {types_loss}\")"
      ],
      "metadata": {
        "id": "htEf8IzpD6r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_pred_accuracy(pred_types, ref_types):\n",
        "  mat = [[0 for i in range(20)] for j in range(20)]\n",
        "  pred_idx = torch.argmax(pred_types, dim=-1)\n",
        "  ref_idx = torch.argmax(ref_types, dim=-1)\n",
        "  for i in range(len(pred_idx)):\n",
        "    mat[ref_idx[i].item()][pred_idx[i].item()] += 1\n",
        "  return mat\n",
        "\n",
        "mat = get_class_pred_accuracy(vld_types_o, vld_types)\n",
        "mat = np.array(mat)\n",
        "row_sums = mat.sum(axis=1, keepdims=True)\n",
        "mat = mat / row_sums\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "ax = sns.heatmap(mat, annot=True, fmt=\".2f\", cmap='viridis', annot_kws={\"size\": 7})\n",
        "plt.title('Heatmap of Real vs Predicted Classes')\n",
        "plt.xlabel('Predicted Classes')\n",
        "plt.ylabel('Real Classes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BdQKWGykYv9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_n = 5\n",
        "test_data = torch.cat([vld_infos[0:5], vld_infos_o[0:5]], dim=1)\n",
        "print(test_data)\n",
        "infos_loss = get_infos_loss(vld_infos_o, vld_infos).item()\n",
        "print(f\"infos_loss = {infos_loss}\")"
      ],
      "metadata": {
        "id": "My7RAbya4ovO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = (vld_stats_o, vld_types_o, vld_infos_o)\n",
        "ref = (vld_s_stats, vld_types, vld_infos)\n",
        "full_loss = get_full_loss(pred, ref).item()\n",
        "print(f\"full_loss = {full_loss}\")"
      ],
      "metadata": {
        "id": "bbKzpdiVDJQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "if True:\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/logs\")\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    shutil.rmtree(\"/content/my_model\")\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "FXmvd4CJuHZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}